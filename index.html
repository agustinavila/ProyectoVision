<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ProyectoVision: Proyecto Vision</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ProyectoVision
   &#160;<span id="projectnumber">0.3</span>
   </div>
   <div id="projectbrief">Proyecto realizado para las materias c++ y vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Proyecto Vision </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><b>test</b></p>
<p>Proyecto final para las materias "Vision Artificial" y "Complementos de Informatica" El proyecto consiste en una clase capaz de obtener imagenes de distintos medios, detectar rostros, obtener puntos de interés y analizar su simetria. Ademas, puede registrar tanto el video adquirido como los puntos de interés detectados. Estos datos provistos pueden ser utilizados para detectar momentos donde la asimetria sea maxima o donde se detecte claramente cierta expresion facial (sonrisa, ceño fruncido, levantar cejas, etc). La idea de la implementación está basada en <a href="https://www.mdpi.com/2076-3417/11/5/2435" title="Facial Paralysis Detection on Images Using Key Point Analysis">este paper</a>.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Uso del programa de ejemplo</h1>
<p>El programa lee la configuración del archivo <a href="config.yaml">config.yaml</a></p>
<ul>
<li>Presionando la tecla <code>o</code> se utiliza el extractor de landmarks de openCV</li>
<li>Presionando la tecla <code>d</code> se utiliza el extractor de landmarks de dlib</li>
<li>Presionando la tecla <code>w</code> se intenta obtener imágenes de una webcam</li>
<li>Presionando la tecla <code>k</code> se intenta obtener imágnees de una kinect</li>
<li>Presionando la tecla <code>v</code> se intenta abrir un archivo de video (por defecto, 'video.avi').</li>
<li>Presionando la tecla <code>q</code> se termina la ejecución.</li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
Desarrollo</h1>
<p>El software consiste en una clase base que se compone de otras subclases. Luego, los objetos concretos de estas clases interactúan entre sí.</p>
<p><img src="/Diagrama/AnalizadorSimetria.png" alt="Esquema de composición de la clase base" class="inline"/>.</p>
<p>Esquema de composición de la clase base.</p>
<p><img src="/Diagrama/proyectoVision.png" alt="Esquema del flujo de trabajo interno" class="inline"/>.</p>
<p>Esquema de las relaciones internas entre clases.</p>
<p>El sistema instancia los objetos necesarios a partir de un <a href="config.yaml">archivo de configuración provisto</a>, con las clases concretas necesarias segun el caso. Si no se pasan argumentos, intenta cargar una configuración por defecto, abriendo una webcam y utilindo un archivo de entrenamiento por defecto.</p>
<p>Además, se incluye el <a href="maintProyectoVision.cc">código</a> para probar diversas funcionalidades de la clase.</p>
<h1><a class="anchor" id="autotoc_md3"></a>
Clases</h1>
<p>A continuacion, se detallan las distintas clases base que compondran al sistema.</p>
<h2><a class="anchor" id="autotoc_md4"></a>
Clase Feeder</h2>
<p>Clase encargada de obtener los fotogramas a analizar. De ésta se derivan tres clases para proveer frames de distintos medios. Las tres clases que heredan de <a class="el" href="class_feeder.html" title="Clase abstracta para proveer obtener nuevos mats.">Feeder</a>, serán:</p>
<ul>
<li><a class="el" href="class_video_feeder.html" title="Sobrecarga de la clase Feeder para abrir un archivo de video.">VideoFeeder</a>, pensada para trabajar con videos.</li>
<li><a class="el" href="class_webcam_feeder.html" title="Sobrecarga de la clase Feeder para abrir una webcam.">WebcamFeeder</a>, pensada para adquirir fotogramas de una webcam.</li>
<li><a class="el" href="class_kinect_feeder.html" title="Sobrecarga de la clase Feeder para proveer objetos Mat desde una kinect.">KinectFeeder</a>, pensada para adquirir fotogramas de una kinect utilizando libfreenect2.</li>
</ul>
<p>Estas clases tendrán un método general para devolver un fotograma del tipo <code>cv::Mat</code> que serán utilizados por los objetos de las clases (<a href="#clase-framelogger">FrameLogger</a> y <a href="#clase-extractorlandmarks">ExtractorLandmarks</a>).</p>
<p><img src="/Diagrama/feeder.png" alt="Ejemplo del Feeder" class="inline"/></p>
<p>Ejemplo en UML de la clase "feeder"</p>
<h2><a class="anchor" id="autotoc_md5"></a>
Clase FrameLogger</h2>
<p>Esta clase está encargada de registrar los frames provistos por el <a href="#clase-feeder">Feeder</a>. Por el momento, va registrando los fotogramas en un video por defecto. Debe tener un metodo de actualizacion que consista en guardar el archivo de imagen en algun lugar en particular, con un nombre que lo identifique unicamente, y que de alguna manera quede linkeado a una "base de datos".</p>
<h2><a class="anchor" id="autotoc_md6"></a>
Clase ExtractorLandmarks</h2>
<p>Esta clase está encargada de obtener los puntos de interés de un rostro a partir de las imágenes provistas por el <a href="#clase-feeder">Feeder</a>. Esta clase abstracta en principio tiene dos implementaciones:</p>
<ul>
<li>clase <a class="el" href="class_extractor_landmarks_open_c_v.html" title="Clase concreta derivada de ExtractorLandmarks para extraer landmarks utilizando openCV.">ExtractorLandmarksOpenCV</a>, utilizando openCV</li>
<li>clase <a class="el" href="class_extractor_landmarks_dlib.html" title="Implementación concreta de la clase abstracta ExtractorLandmarks usando dlib.">ExtractorLandmarksDlib</a>, utilizando dlib</li>
</ul>
<p>Estas dos clases utilizarían distintos algoritmos para la deteccion de puntos de interes, basados en distintos papers y con distintos entrenamientos.</p>
<p><img src="/Diagrama/extractorLandmarks.png" alt="Ejemplo del Feeder" class="inline"/></p>
<p>Diagrama UML de la clase <a class="el" href="class_extractor_landmarks.html" title="Clase abstracta para extraer landmarks de un Mat.">ExtractorLandmarks</a></p>
<h3><a class="anchor" id="autotoc_md7"></a>
Clase ExtractorLandmarksOpenCV</h3>
<p>Esta clase está basada en las librerias de openCV. Necesita los archivos <code>haarcascade_frontalface_alt2.xml</code> y <code>lbfmodel.yaml</code>.</p>
<h3><a class="anchor" id="autotoc_md8"></a>
Clase ExtractorLandmarksDlib</h3>
<p>Esta clase está basada en las librerias de dlib. Necesita el archivo <code>shape_predictor_68_face_landmarks.dat</code>, obtenido del código de ejemplo de dlib.</p>
<h2><a class="anchor" id="autotoc_md9"></a>
Clase AnalizadorLandmarks</h2>
<p>Esta clase normaliza los puntos de interés provistos por el <a href="#clase-extractorlandmarks">extractor de landmarks</a>, es decir, corrige la inclinacion de la cabeza, tomando como referencias los puntos a mitad de cada oreja. Con esto, calcula la simetria de la cara basándose en algunos puntos particulares(Elegidos medio aleatoriamente) Respecto a la simetria, la clase será la encargada de analizar los puntos de interés normalizados, haciendo algunos calculos geométricos y devolviendo distintas medidas sobre la simetria facial. En el <a href="https://www.mdpi.com/2076-3417/11/5/2435" title="Facial Paralysis Detection on Images Using Key Point Analysis">paper</a> de referencia, estas medidas se utilizan para luego alimentar un clasificador. Al no tener acceso a los datasets para poder "clasificar" distintos rostros, este ultimo paso se dificulta. Aun asi, debe ser posible obtener un puntaje analizando distintas medidas y comparando ambos lados del rostro. Además, el normalizador podria filtrar solo los landmarks necesarios para el calculo de simetria, reduciendo asi el tamaño de los datos guardados. Finalmente, la clase devuelve un vector de <a href="#estructura-landmarks">una estructura predefinida</a>, habiendo una estructura por cada rostro detectado.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Clase LandmarksLogger</h2>
<p>Esta clase está encargada de registrar cada vector de <a href="#estructura-landmarks">landmarks</a> obtenido. Registra los datos en un archivo de tipo YAML, tomando un nombre de base y agregandole el tipo de feeder utilizado y un timestamp.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Estructura Landmarks</h1>
<p>Es la estructura que devuelve el extractor de landmarks para facilitar su uso. Está compuesta por las siguientes propiedades:</p>
<ul>
<li>vacio : Bandera para detectar si la estructura posee información</li>
<li>rotacion : Indica la rotación de la cabeza, en caso de haberse normalizado.</li>
<li>escala : Indica la escala de los puntos, en caso de haberse normalizado.</li>
<li>menton : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan el mentón.</li>
<li>ojoIzq : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan el ojo izquierdo.</li>
<li>ojoDer : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan el ojo derecho.</li>
<li>cejaIzq : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan la ceja izquierda.</li>
<li>cejaDer : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan la ceja derecha.</li>
<li>boca : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan la boca.</li>
<li>nariz : <code>std::vector&lt;cv::Point2f&gt;</code> vector de puntos de openCV que demarcan la nariz.</li>
</ul>
<h1><a class="anchor" id="autotoc_md12"></a>
Dependencias</h1>
<ul>
<li><a href="http://dlib.net/">dlib</a> (utilizada version 19.22)</li>
<li><a href="https://github.com/OpenKinect/libfreenect2">libfreenect2</a> (utilizada version 0.2.0)</li>
<li><a href="https://github.com/opencv/open">openCV</a> (utilizada version 4.5.2)</li>
</ul>
<p>Además, se utilizaron diversas librerias requeridas por estos paquetes (principalmente por libfreenect2) que están mencionadas en el comando de compilación.</p>
<h1><a class="anchor" id="autotoc_md13"></a>
TODO</h1>
<ul>
<li>[ ] Sobrecarga de operadores <code>&lt;&lt;</code> y <code>&gt;&gt;</code> para la entrada y salida de archivos.</li>
<li>[ ] Algoritmo de ordenamiento de los vectores de landmarks (utilizando como referencia la asimetria).</li>
<li>[ ] Procesar datos guardados previamente.</li>
<li>[ ] Generar una interfaz en Qt.</li>
<li>[ ] Generalizar el <a class="el" href="class_feeder.html" title="Clase abstracta para proveer obtener nuevos mats.">Feeder</a> para poder incorporar, por ejemplo, imágenes de profundidad , RGBD o IR desde kinect.</li>
<li>[ ] Realizar una implementación mejorada del calculador de asimetría (es una funcion dummy, hace un par de calculos basicos).</li>
<li>[ ] Utilizar threads para distintas tareas(principalmente las que requieren acceso al disco) y así optimizar el funcionamiento general.</li>
<li>[ ] Desarrollar en mayor profundidad el programa de ejemplo mainProyectoVision.</li>
<li>[ ] Manejo de señales, para que si se interrumpe salga limpiamente.</li>
</ul>
<h1><a class="anchor" id="autotoc_md14"></a>
Desarrollo y compilación</h1>
<p>Para el desarrollo de este software, se utilizó el editor de texto Visual Studio Code, ya que facilitaba y automatizaba muchas tareas con las correspondientes extensiones (Generador de UML, comentarios automáticos para Doxygen, snippets de código, autocompletar código, generación de distintas tareas de compilación). Para compilarlo, se utilizó el siguiente comando: <code>g++ -Wall -DUSE_AVX_INSTRUCTIONS=ON /home/agustin/Facultad/5to/ProyectoVision/*.cc</code> <code>/home/agustin/Facultad/5to/ProyectoVision/include/src/*.cc</code> <code>-o /home/agustin/Facultad/5to/ProyectoVision/Release/mainProyectoVision</code> <code>-I/home/agustin/Facultad/5to/ProyectoVision/include -I/usr/include/</code> <code>-I/usr/local/lib/ -I/usr/local/include -I/usr/local/include/opencv4</code> <code>-L/usr/local/freenect2/lib -L/usr/lib -lopencv_core -lopencv_highgui</code> <code>-lopencv_imgcodecs -lopencv_video -lopencv_videoio -lopencv_plot</code> <code>-lopencv_objdetect -lopencv_imgproc -lopencv_face -ldlib -lturbojpeg</code> <code>-ljpeg -lfreenect2 -llapack -lopenblas -O3</code></p>
<p>Generado con el archivo <a href=".vscode/tasks.json">tasks.json</a> en Visual Studio Code. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
